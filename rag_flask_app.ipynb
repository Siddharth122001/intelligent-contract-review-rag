{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8uT8rwOO0q4",
        "outputId": "3b0b5319-679a-46cb-b536-c8fbb0db2550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install flask faiss-cpu sentence-transformers transformers torch pdfplumber pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq4jvx-jQHod",
        "outputId": "e83dd112-dac5-418a-a7bc-a3890ec6a77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flask pyngrok sentence-transformers transformers\n"
      ],
      "metadata": {
        "id": "jq7tme5BQRdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import pickle\n",
        "\n",
        "index = faiss.read_index(\"cuad_faiss.index\")\n",
        "\n",
        "with open(\"all_chunks.pkl\", \"rb\") as f:\n",
        "    all_chunks = pickle.load(f)\n",
        "\n",
        "print(\"FAISS + chunks loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "8n9_azPmPk6i",
        "outputId": "9b04ecd6-4866-4ddf-d0a7-efb79f941ee5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error in faiss::FileIOReader::FileIOReader(const char*) at /project/third-party/faiss/faiss/impl/io.cpp:69: Error: 'f' failed: could not open cuad_faiss.index for reading: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-737166726.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuad_faiss.index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all_chunks.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/faiss/swigfaiss_avx2.py\u001b[0m in \u001b[0;36mread_index\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m  13056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13057\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 13058\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  13059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13060\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_index_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/third-party/faiss/faiss/impl/io.cpp:69: Error: 'f' failed: could not open cuad_faiss.index for reading: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(device)\n"
      ],
      "metadata": {
        "id": "iKkor4JVrR3c"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_chunks(query, top_k=5):\n",
        "    q_emb = embed_model.encode(\n",
        "        [query],\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "    scores, idx = index.search(q_emb, top_k)\n",
        "    return [all_chunks[i] for i in idx[0]]\n"
      ],
      "metadata": {
        "id": "O7WLY5ejs2GK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_vendor_risks(chunks):\n",
        "    risks = {}\n",
        "\n",
        "    rules = {\n",
        "        \"Indemnification Risk\": {\n",
        "            \"keywords\": [\"indemnify\", \"indemnification\"],\n",
        "            \"severity\": \"High\",\n",
        "            \"summary\": \"Indemnification obligations may expose the vendor to long-term liability.\"\n",
        "        },\n",
        "        \"Liability & Damages Risk\": {\n",
        "            \"keywords\": [\"limitation of liability\", \"liable\", \"consequential\", \"punitive\"],\n",
        "            \"severity\": \"High\",\n",
        "            \"summary\": \"Liability limitations and damage exclusions may significantly shift risk.\"\n",
        "        },\n",
        "        \"Termination Risk\": {\n",
        "            \"keywords\": [\"termination\", \"terminate\"],\n",
        "            \"severity\": \"Medium\",\n",
        "            \"summary\": \"Certain obligations survive termination, increasing post-contract exposure.\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for chunk in chunks:\n",
        "        lower = chunk.lower()\n",
        "        for risk, rule in rules.items():\n",
        "            if any(k in lower for k in rule[\"keywords\"]):\n",
        "                if risk not in risks:\n",
        "                    risks[risk] = {\n",
        "                        \"risk\": risk,\n",
        "                        \"severity\": rule[\"severity\"],\n",
        "                        \"summary\": rule[\"summary\"],\n",
        "                        \"evidence\": chunk.strip().split(\".\")[0] + \".\"\n",
        "                    }\n",
        "\n",
        "    return list(risks.values())\n"
      ],
      "metadata": {
        "id": "nPMXuHels2Ji"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query, top_k=5):\n",
        "    # 1ï¸âƒ£ Retrieve relevant chunks using FAISS\n",
        "    chunks = retrieve_chunks(query, top_k)\n",
        "\n",
        "    # 2ï¸âƒ£ RISK MODE (your code goes HERE ğŸ‘‡)\n",
        "    if \"risk\" in query.lower():\n",
        "        risks = analyze_vendor_risks(chunks)\n",
        "\n",
        "        if not risks:\n",
        "            return \"No material vendor risks identified in this contract.\", []\n",
        "\n",
        "        answer = \"âš ï¸ Identified Contract Risks\\n\\n\"\n",
        "\n",
        "        for i, r in enumerate(risks, 1):\n",
        "            answer += (\n",
        "                f\"{i}ï¸âƒ£ {r['risk']} ({r['severity']})\\n\"\n",
        "                f\"â€¢ {r['summary']}\\n\"\n",
        "                f\"â€¢ Evidence: {r['evidence']}\\n\\n\"\n",
        "            )\n",
        "\n",
        "        # â›” Important: do NOT return chunks again\n",
        "        return answer, []\n",
        "\n",
        "    # 3ï¸âƒ£ NORMAL QUESTION-ANSWER MODE\n",
        "    context = \"\\n\\n\".join(chunks)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a legal assistant.\n",
        "Answer the question using ONLY the context below.\n",
        "If the answer is not present, say \"Not found in contract.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=1024\n",
        "    ).to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=250,\n",
        "        temperature=0.2,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    if \"Answer:\" in decoded:\n",
        "        decoded = decoded.split(\"Answer:\")[-1].strip()\n",
        "\n",
        "    return decoded, chunks\n"
      ],
      "metadata": {
        "id": "00B5pcSytE9z"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "\n",
        "@app.route(\"/ask\", methods=[\"POST\"])\n",
        "def ask():\n",
        "    query = request.form.get(\"query\")\n",
        "\n",
        "    # ğŸ‘‡ CALL your RAG function\n",
        "    answer, chunks = generate_answer(query)\n",
        "\n",
        "    # ğŸ‘‡ UI decision logic (THIS is where your code belongs)\n",
        "    show_chunks = False if \"risk\" in query.lower() else True\n",
        "\n",
        "    return render_template(\n",
        "        \"index.html\",\n",
        "        answer=answer,\n",
        "        chunks=chunks if show_chunks else None,\n",
        "        query=query\n",
        "    )\n"
      ],
      "metadata": {
        "id": "qjJjwcKptFBV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "html = \"\"\"<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Intelligent Contract Review Assistant</title>\n",
        "\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            margin: 40px;\n",
        "            background-color: #fafafa;\n",
        "        }\n",
        "\n",
        "        h1 {\n",
        "            color: #333;\n",
        "        }\n",
        "\n",
        "        input[type=\"text\"] {\n",
        "            width: 70%;\n",
        "            padding: 12px;\n",
        "            font-size: 14px;\n",
        "        }\n",
        "\n",
        "        button {\n",
        "            padding: 12px 20px;\n",
        "            font-size: 14px;\n",
        "            background-color: #1976d2;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "\n",
        "        button:hover {\n",
        "            background-color: #125aa3;\n",
        "        }\n",
        "\n",
        "        .answer-box {\n",
        "            background-color: #fff8e1;\n",
        "            border-left: 6px solid #ff9800;\n",
        "            padding: 20px;\n",
        "            margin-top: 30px;\n",
        "        }\n",
        "\n",
        "        .chunks-box {\n",
        "            background-color: #f4f4f4;\n",
        "            padding: 20px;\n",
        "            margin-top: 20px;\n",
        "            border-left: 6px solid #9e9e9e;\n",
        "        }\n",
        "\n",
        "        pre {\n",
        "            white-space: pre-wrap;\n",
        "            font-family: Arial, sans-serif;\n",
        "            font-size: 14px;\n",
        "        }\n",
        "\n",
        "        hr {\n",
        "            margin: 15px 0;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "<h1>ğŸ“„ Intelligent Contract Review Assistant (RAG)</h1>\n",
        "<p>\n",
        "    Ask questions like:\n",
        "    <i>\"termination conditions\", \"payment terms\", \"vendor risk\"</i>\n",
        "</p>\n",
        "\n",
        "<form method=\"POST\" action=\"/ask\">\n",
        "    <input\n",
        "        type=\"text\"\n",
        "        name=\"query\"\n",
        "        placeholder=\"Ask a question about the contract...\"\n",
        "        value=\"{{ query or '' }}\"\n",
        "        required\n",
        "    >\n",
        "    <button type=\"submit\">Ask</button>\n",
        "</form>\n",
        "\n",
        "{% if answer %}\n",
        "<div class=\"answer-box\">\n",
        "    <h3>âœ… Answer</h3>\n",
        "    <pre>{{ answer }}</pre>\n",
        "</div>\n",
        "{% endif %}\n",
        "\n",
        "{% if chunks %}\n",
        "<div class=\"chunks-box\">\n",
        "    <h3>ğŸ“Œ Retrieved Contract Evidence</h3>\n",
        "    {% for c in chunks %}\n",
        "        <hr>\n",
        "        <pre>{{ c }}</pre>\n",
        "    {% endfor %}\n",
        "</div>\n",
        "{% endif %}\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "with open(\"templates/index.html\", \"w\") as f:\n",
        "    f.write(html)\n"
      ],
      "metadata": {
        "id": "BQj90-8Ztl-k"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"38z8e7xeNGIQnptGouLvTsDGMAt_7MYXfJP2ZJy2G4wLKf3Vc\")\n"
      ],
      "metadata": {
        "id": "huXXbBIZFOZO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "\n",
        "Thread(target=lambda: app.run(host=\"0.0.0.0\", port=5000, debug=False, use_reloader=False)).start()\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"ğŸŒ Public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq0jIb0GuVen",
        "outputId": "e6683ba5-f23a-4e87-cfc5-0f9bcf5ee4f1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒ Public URL: NgrokTunnel: \"https://luis-meek-noriko.ngrok-free.dev\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    }
  ]
}